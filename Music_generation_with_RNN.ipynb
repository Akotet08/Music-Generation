{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "povoYS_9Ed7P"
      },
      "outputs": [],
      "source": [
        "# This is an LSTM network that will be used for generating music based on the \n",
        "# Irish song dataset provided"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-liRsAdHWfi"
      },
      "source": [
        "# Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k6CQuwpE9ZQ",
        "outputId": "78b42143-1d82-452c-81b2-2938e2052436"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "!apt-get install abcmidi timidity \n",
        "\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVeEzd8JHbz_"
      },
      "source": [
        "# Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbTA4HxHkvD"
      },
      "source": [
        "The Irish songs are in abc format in the file irish.abc. There are a total of 817 songs in the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKGY2KNIRQTQ"
      },
      "outputs": [],
      "source": [
        "# !/bin/bash abc2wav tmp.abc\n",
        "# os.system('/bin/bash abc2wav tmp.abc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ejbxYgmITIA"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "import subprocess\n",
        "\n",
        "\n",
        "cwd = os.path.dirname('./content')\n",
        "\n",
        "def save_song_to_abc(song, filename=\"tmp\"):\n",
        "    save_name = \"{}.abc\".format(filename)\n",
        "    with open(save_name, \"w\") as f:\n",
        "        f.write(song)\n",
        "    return filename\n",
        "\n",
        "def abc2wav(abc_file):\n",
        "    path_to_tool = os.path.join(cwd, 'abc2wav')\n",
        "    # cmd = \"{} {}\".format(path_to_tool, abc_file)\n",
        "    cmd = '/bin/bash abc2wav tmp.abc'\n",
        "    return os.system(cmd)\n",
        "\n",
        "def play_wav(wav_file):\n",
        "    return Audio(wav_file)\n",
        "\n",
        "def play_song(song):\n",
        "    basename = save_song_to_abc(song)\n",
        "    ret = abc2wav(basename+'.abc')\n",
        "    if ret == 0: #did not suceed\n",
        "        return play_wav(basename+'.wav')\n",
        "    return None\n",
        "\n",
        "def play_generated_song(generated_text):\n",
        "    songs = extract_song_snippet(generated_text)\n",
        "    if len(songs) == 0:\n",
        "        print(\"No valid songs found in generated text. Try training the \\\n",
        "            model longer or increasing the amount of generated music to \\\n",
        "            ensure complete songs are generated!\")\n",
        "\n",
        "    for song in songs:\n",
        "        play_song(song)\n",
        "    print(\"None of the songs were valid, try training longer to improve \\\n",
        "        syntax.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id7y_AuEFPjp",
        "outputId": "132ffb45-1cf6-43fd-e1dd-87c99baa680b"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "\n",
        "def extract_song_snippet(generated_text):\n",
        "  pattern = '(^|\\n\\n)(.*?)\\n\\n'\n",
        "  search_results = re.findall(pattern, text, overlapped=True, flags=re.DOTALL)\n",
        "  songs = [song[1] for song in search_results]\n",
        "\n",
        "  return songs\n",
        "\n",
        "songs = []\n",
        "filename = 'irish.abc'\n",
        "with open(filename, 'r') as file:\n",
        "  text = file.read()\n",
        "  songs = extract_song_snippet(text)\n",
        "\n",
        "print( f'Number of songs: {len(songs)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "wbavdgVNM1yN",
        "outputId": "9ce3a794-be2c-4bd2-bd1b-f15a0c869040"
      },
      "outputs": [],
      "source": [
        "# play example song\n",
        "play_song(songs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVikclnLWtQ_"
      },
      "source": [
        "### Process the dataset for generation task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88OndklpOcVx",
        "outputId": "be923807-3f92-4060-c774-5c0b5b1dbfb9"
      },
      "outputs": [],
      "source": [
        "# extract the vocabulary\n",
        "\n",
        "songs_str = '\\n\\n'.join(songs)\n",
        "vocab = sorted(set(songs_str))\n",
        "print(f'There are {len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJKj3j89XLQ9",
        "outputId": "5e9db97d-9d68-4123-c4f1-9016b5fed09e"
      },
      "outputs": [],
      "source": [
        "# Look up table\n",
        "\n",
        "# character to index\n",
        "char2idx = {c:i for i, c in enumerate(vocab)}\n",
        "print(char2idx)\n",
        "\n",
        "# index to character\n",
        "idx2char = np.array(vocab)\n",
        "print(idx2char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwfzwQNgY2sB"
      },
      "source": [
        "### vectorize String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BaI00wKYawO",
        "outputId": "d7feb3f0-8521-4177-b194-55745c2e503f"
      },
      "outputs": [],
      "source": [
        "# Given a string returns a vector based the lookup table above\n",
        "def vectorize(string):\n",
        "  vector = [char2idx[char] for char in string]\n",
        "  return np.array(vector)\n",
        "\n",
        "# vectorize the dataset\n",
        "vectorized_songs = vectorize(songs_str)\n",
        "vectorized_songs.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT2PDzjKc2DG"
      },
      "source": [
        "### Generating Batches\n",
        "Each batch will have length of seq_length. The input batch and the output batch have the same lenght but the output batch is shifted one character to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl-dMLbVZXN6"
      },
      "outputs": [],
      "source": [
        "# generate batches\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  n = vectorized_songs.shape[0] - 1 \n",
        "  # random indexes to start the sequence from\n",
        "  idx = np.random.choice(n - seq_length, batch_size)\n",
        "\n",
        "  # input and output batch. Output batch shifted to the right by one character\n",
        "  input_batch = [vectorized_songs[i: i + seq_length] for i in idx]\n",
        "  output_batch = [vectorized_songs[i+1: i+1 + seq_length] for i in idx]\n",
        "\n",
        "  x_batch = np.reshape(input_batch, (batch_size, seq_length))\n",
        "  y_batch = np.reshape(output_batch, (batch_size, seq_length))\n",
        "\n",
        "  return x_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71RciWTrfkeS",
        "outputId": "176269d8-984c-4e0c-ec2e-5b74f9afb3b1"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW5eJlYBhvWr"
      },
      "source": [
        "# The RNN Model\n",
        "The RNN model has Three Layers\n",
        "\n",
        "*  `tf.keras.layers.Embedding`- The input layer with a trainable lookup table that maps each number to a vector of dimensions `embedding_dim`\n",
        "*  `tf.keras.layers.LSTM` - The RNN with size rnn_units\n",
        "*  `tf.keras.layers.Dense` - The final layer to output the probability distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JGsRxPPftAO"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      # Layer 1: Embedding layer\n",
        "      # input shape: vocab_size\n",
        "      # output shape: embedding_dim\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]), \n",
        "\n",
        "      # Layer 2: LSTM layer\n",
        "      tf.keras.layers.LSTM(units=rnn_units, \n",
        "                           return_sequences=True, \n",
        "                           recurrent_initializer='glorot_uniform',\n",
        "                           recurrent_activation='sigmoid',\n",
        "                           stateful=True,),\n",
        "\n",
        "      # Layer 3: Dense Layer\n",
        "      tf.keras.layers.Dense(units = vocab_size)\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKnYmkbhmjXN"
      },
      "outputs": [],
      "source": [
        "num_training_iterations = 2000\n",
        "batch_size = 32\n",
        "seq_length = 100\n",
        "learning_rate = 1e-3\n",
        "\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'my_ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rXed3P6nR1-"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y_true, y_pred):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits = True)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPOaYzjVrxkd"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_hat = model(x)\n",
        "\n",
        "    loss = compute_loss(y, y_hat)\n",
        "  \n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFSgu2DHuHXD",
        "outputId": "e7a8943b-e05f-4344-9e0b-60351621ccd1"
      },
      "outputs": [],
      "source": [
        "history = []\n",
        "# plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "for iter in tqdm(range(num_training_iterations)):\n",
        "\n",
        "  # Grab a batch and propagate it through the network\n",
        "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "\n",
        "  # Update the progress bar\n",
        "  history.append(loss.numpy().mean())\n",
        "  # plotter.plot(history)\n",
        "\n",
        "  # Update the model with the changed weights!\n",
        "  if iter % 100 == 0:     \n",
        "    model.save_weights(checkpoint_prefix)\n",
        "    \n",
        "# Save the trained model and the weights\n",
        "model.save_weights(checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ucQ2EfZIvjDb",
        "outputId": "deff6bf7-de4a-41a1-b1fc-4dc6006c5b66"
      },
      "outputs": [],
      "source": [
        "# visualizing the loss function\n",
        "x = [i for i in range(2000)]\n",
        "plt.plot(x, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbeKFDYUwEjI",
        "outputId": "7d2b0a5a-8eca-4db2-dcad-9a2bf71e6cb5"
      },
      "outputs": [],
      "source": [
        "'''TODO: Rebuild the model using a batch_size=1'''\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW5s3o3Rw1BF"
      },
      "outputs": [],
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "  '''TODO: convert the start string to numbers (vectorize)'''\n",
        "  input_eval = [char2idx[i] for i in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "      '''TODO: evaluate the inputs and generate the next character predictions'''\n",
        "      predictions = model(input_eval)\n",
        "      \n",
        "      # Remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      \n",
        "      '''TODO: use a multinomial distribution to sample'''\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      \n",
        "      # Pass the prediction along with the previous hidden state\n",
        "      #   as the next inputs to the model\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      \n",
        "      '''TODO: add the predicted character to the generated text!'''\n",
        "      # Hint: consider what format the prediction is in vs. the output\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "    \n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "mhpBXx98w6ib",
        "outputId": "76be67f8-03a3-4488-dc53-a48d2775423a"
      },
      "outputs": [],
      "source": [
        "generated_text = generate_text(model, start_string=\"#\", generation_length=1000) # TODO\n",
        "generated_songs = extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs): \n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it! \n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn9i4tTUxF_j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
